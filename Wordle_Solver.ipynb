{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjconnell/Wordle_Solver/blob/main/Wordle_Solver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70KqAjkyiup5",
        "outputId": "d0fc553a-92bc-4d72-c228-eff2d979d0a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qWaIWssJir1o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import urllib\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eKM8GHj_ir1v"
      },
      "outputs": [],
      "source": [
        "def ltr_freq(temp):\n",
        "    # calculate frequency of letters in each position for remaining words\n",
        "    ltr_den = np.zeros((26,5))\n",
        "    \n",
        "    alphabet = ['A', 'B','C','D','E','F',\n",
        "                'G','H','I','J','K','L',\n",
        "                'M','N','O','P','Q','R',\n",
        "                'S','T','U','V','W','X',\n",
        "                'Y','Z']\n",
        "    positions = ['pos_1','pos_2','pos_3','pos_4','pos_5']\n",
        "    \n",
        "    # df to hold density counts\n",
        "    df = pd.DataFrame(ltr_den, columns = positions,index=alphabet)\n",
        "\n",
        "    #iterate through temp to count letter freq in each position\n",
        "    for i in tqdm(range(len(temp))):\n",
        "        for j in range(0,5):\n",
        "            for k in range(len(alphabet)):\n",
        "                if temp[i][j] == alphabet[k]:\n",
        "                    df[positions[j]][k]+=1.0\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "NztZCWaNir1v"
      },
      "outputs": [],
      "source": [
        "def update_wd_list(contains, excludes, pos_str, non_pos, temp):\n",
        "    for i in range(len(contains)):\n",
        "        temp = [word for word in temp if contains[i] in word]\n",
        "\n",
        "    for i in range(len(excludes)):\n",
        "        temp = [word for word in temp if excludes[i] not in word]\n",
        "\n",
        "    for i in range(len(pos_str)):\n",
        "        if pos_str[i] != '?':\n",
        "            temp = [word for word in temp if word[i] == pos_str[i]]\n",
        "\n",
        "    for i in range(len(non_pos)):\n",
        "        if len(non_pos[i]) >0:\n",
        "            for j in range(len(non_pos[i])):\n",
        "                if non_pos[i][j] != '?':\n",
        "                    temp = [word for word in temp if word[j] != non_pos[i][j]]\n",
        "    return temp\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def guess_wd(temp):\n",
        "  # set df with updated word list and column to hold value of guessing word\n",
        "  temp2 = pd.DataFrame(temp,columns =['word'])\n",
        "  temp2['guess_val']=0.0\n",
        "\n",
        "  for i in tqdm(range(temp2.shape[0])):\n",
        "    wd = temp2.word[i]\n",
        "    for j in range(len(temp2.word[i])):\n",
        "      # calculate expected value of letter in that position\n",
        "      ev_1 = (df[positions[j]][wd[j].upper()]/temp2.shape[0])*(temp2.shape[0]-df[positions[j]][wd[j].upper()])\n",
        "\n",
        "      if j == 0:\n",
        "        # calculate expected value of letter in word, but not in that position\n",
        "        ev_2 = ((df.sum(axis=1)[wd[j].upper()]-df[positions[j]][wd[j].upper()])/(temp2.shape[0]))*(temp2.shape[0]-(df.sum(axis=1)[wd[j].upper()]-df[positions[j]][wd[j].upper()]))\n",
        "\n",
        "        # calculate expected value of the letter not being in that word\n",
        "        ev_3 = ((temp2.shape[0]-df.sum(axis=1)[wd[j].upper()])/(temp2.shape[0]))*(df.sum(axis=1)[wd[j].upper()])\n",
        "      \n",
        "      if j > 0: # don't want to double count the benefit of ruling out letters that occur more than once\n",
        "        # to check if letter is repeated, define word without letter\n",
        "        w2 = wd[:j]+wd[j+1:]\n",
        "        \n",
        "        if wd[j] in w2:\n",
        "          ev_2 = 0\n",
        "          ev_3 =0\n",
        "        elif wd[j] not in w2:\n",
        "          # calculate expected value of letter in word, but not in that position\n",
        "          ev_2 = ((df.sum(axis=1)[wd[j].upper()]-df[positions[j]][wd[j].upper()])/(temp2.shape[0]))*(temp2.shape[0]-(df.sum(axis=1)[wd[j].upper()]-df[positions[j]][wd[j].upper()]))\n",
        "\n",
        "          # calculate expected value of the letter not being in that word\n",
        "          ev_3 = ((temp2.shape[0]-df.sum(axis=1)[wd[j].upper()])/(temp2.shape[0]))*(df.sum(axis=1)[wd[j].upper()])\n",
        "\n",
        "      # add to total expected value\n",
        "      ltr_ev = ev_1+ev_2+ev_3\n",
        "      temp2.guess_val[i] += ltr_ev\n",
        "      \n",
        "  return temp2.word[temp2.guess_val.idxmax()]"
      ],
      "metadata": {
        "id": "2ktPfU0UX7Pv"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "5CCAuS7sir1u"
      },
      "outputs": [],
      "source": [
        "# # load df from pickle\n",
        "# # be sure to have the scrabble dictionary text file saved to your Google drive\n",
        "use_df = pd.read_pickle('/content/drive/MyDrive/Wordle Solver/wds_mc.pickle') # get our list of valid guesses\n",
        "use_df.columns = ['word','mc']\n",
        "ans_df = use_df.sort_values(by=['mc'], ascending=False)\n",
        "ans_df = ans_df.head(4000) # get our list of potential answers\n",
        "ans_df = ans_df.reset_index(drop=True)\n",
        "\n",
        "# store alphabet as a list\n",
        "alphabet = ['A', 'B','C','D','E','F',\n",
        "            'G','H','I','J','K','L',\n",
        "            'M','N','O','P','Q','R',\n",
        "            'S','T','U','V','W','X',\n",
        "            'Y','Z']\n",
        "\n",
        "# store potential letter positions as a list\n",
        "positions = ['pos_1','pos_2','pos_3','pos_4','pos_5']\n",
        "\n",
        "# create initial density chart\n",
        "df = ltr_freq(ans_df['word'])\n",
        "\n",
        "# create initial answer list\n",
        "temp = ans_df['word']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxQ6gMRJir1x",
        "outputId": "7fdfc48c-33b6-4a4e-b766-f5c4129c35fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter letters the word contains separated by a space: L E A T\n",
            "Enter excluded letters separated by a space: R S D C\n",
            "Enter known positions (e.g., S??A?): ?LEAT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 645.48it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "100%|██████████| 2/2 [00:00<00:00, 100.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You should try: BLEAT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#### Interface - rerun this cell to generate each new guess\n",
        "\n",
        "# ID known letters\n",
        "input_contains = input(\"Enter letters the word contains separated by a space: \")\n",
        "contains = input_contains.split()\n",
        "\n",
        "# ID known excluded letters\n",
        "input_excludes = input(\"Enter excluded letters separated by a space: \")\n",
        "excludes = input_excludes.split()\n",
        "\n",
        "# ID known positions\n",
        "pos_str = input(\"Enter known positions (e.g., S??A?): \")\n",
        "\n",
        "# ID known non-positions\n",
        "non_pos =[\"\",\"\",\"\",\"\",\"\"]\n",
        "for i in range(len(contains)):\n",
        "    if contains[i] not in pos_str:\n",
        "        non_pos[i] = input(f\"Enter known nonpositions for letter {contains[i]} (e.g., {contains[i]}??{contains[i]}?): \")\n",
        "\n",
        "# update frequency counts, remaining word list and generate new guess\n",
        "temp = update_wd_list(contains, excludes, pos_str, non_pos, temp)\n",
        "df = ltr_freq(temp)\n",
        "guess = guess_wd(temp)\n",
        "# if len(guess)<5:\n",
        "#     guess = temp[0]\n",
        "print(f\"You should try: {guess}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp # run this if you want to see which words are still potential answers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVhNDI4cZbG-",
        "outputId": "f94b6f0a-988e-4a8d-8d6f-e4e5d67b109e"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BLEAT', 'PLEAT']"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### note - this takes a couple hours to run and is how the 'wds_mc.pickle' file was created\n",
        "# # read scrabble dictionary to wordlist\n",
        "# with open(\"/content/drive/MyDrive/Wordle Solver/scrabble_dict.txt\") as f:\n",
        "#     wordlist = f.read().splitlines()[2:]\n",
        "\n",
        "# # filter for 5 letter words / no plurals (Wordle doesn't use them)\n",
        "# wordlist = [word for word in wordlist if len(word) == 5 ]\n",
        "# wordlist = [word for word in temp if word[4] != 'S' or word[3] == 'S']\n",
        "\n",
        "# # made df to hold wordlist and wordcounts (to down-weight unlikely scrabble wds)\n",
        "# use_df = pd.DataFrame(wordlist,columns=['words'])\n",
        "# use_df['mc'] = 0\n",
        "\n",
        "# for i in tqdm(range(use_df.shape[0])):\n",
        "#   # do the request from phrasefinder.io to get the number of mentions in corpus\n",
        "#   encoded_query = urllib.parse.quote(temp[i])\n",
        "#   params = {'corpus': 'eng-us', 'query': encoded_query, 'topk': 1}\n",
        "#   params = '&'.join('{}={}'.format(name, value) for name, value in params.items())\n",
        "#   response = requests.get('https://api.phrasefinder.io/search?' + params)\n",
        "#   assert response.status_code == 200\n",
        "\n",
        "#   # add mention count to use_df\n",
        "#   try:\n",
        "#     use_df['mc'][i] = response.json()['phrases'][0]['mc']\n",
        "#   except:\n",
        "#     use_df['mc'][i] = 0\n",
        "\n",
        "# use_df.to_pickle('wds_mc.pickle')"
      ],
      "metadata": {
        "id": "N1YxF27mZK-y"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XQIefeIzvbbl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Wordle Solver.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}